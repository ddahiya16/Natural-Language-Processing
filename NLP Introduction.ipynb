{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will use spaCy library for the following tasks: \n",
    "    \n",
    "    Basic tex processing and pattern matching.\n",
    "    Building machine learning models with text.\n",
    "    Representing text with word embeddings that numerically capture the meaning of words and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the en_core_web_sm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Winners don't do different things, they do the things differently.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return an object that has token.\n",
    "It is a specific unit of text in the document, which includes indiviudal words and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winners\n",
      "do\n",
      "n't\n",
      "do\n",
      "different\n",
      "things\n",
      ",\n",
      "they\n",
      "do\n",
      "the\n",
      "things\n",
      "differently\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few important types of texts, which helps in improving modeling of the words.\n",
    "\n",
    "**Lemma** : It is the base of the word. Eg: Eating is lemmatized to Eat.\n",
    "**Stopword**: These are the words which occurs frequently in english language but contains very little information. \n",
    "Eg: a, the, is, and, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token\t\tLemma \t\tStopword\n",
      "Winners\t\twinner\t\tFalse\n",
      "do\t\tdo\t\tTrue\n",
      "n't\t\tn't\t\tTrue\n",
      "do\t\tdo\t\tTrue\n",
      "different\t\tdifferent\t\tFalse\n",
      "things\t\tthing\t\tFalse\n",
      ",\t\t,\t\tFalse\n",
      "they\t\tthey\t\tTrue\n",
      "do\t\tdo\t\tTrue\n",
      "the\t\tthe\t\tTrue\n",
      "things\t\tthing\t\tFalse\n",
      "differently\t\tdifferently\t\tFalse\n",
      ".\t\t.\t\tFalse\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token\\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But on the other hand, lemmatizing and dropping the stopwards entirely might result in degrading model performance.\n",
    "Rather it should be used for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is matching tokens or phrases within chunks of text or whole documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
    "patterns = [nlp(text) for text in terms]\n",
    "matcher.add(\"TerminologyList\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n"
     ]
    }
   ],
   "source": [
    "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
    "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
    "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\") \n",
    "matches = matcher(text_doc)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TerminologyList iPhone 11\n"
     ]
    }
   ],
   "source": [
    "match_id, start, end = matches[0]\n",
    "print(nlp.vocab.strings[match_id], text_doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
